# preprocess.py
import pandas as pd
import ast

# 1. è®€å–æ¨¡æ“¬å‡ºä¾†çš„åŸå§‹è³‡æ–™
print("æ­£åœ¨è®€å– training_data.csv ...")
try:
    df = pd.read_csv("training_data.csv")
except FileNotFoundError:
    print("âŒ æ‰¾ä¸åˆ° training_data.csvï¼Œè«‹å…ˆåŸ·è¡Œ simulate_gen.py")
    exit()

# 2. æ‰¾å‡ºæ‰€æœ‰å‡ºç¾éçš„å‹•ä½œåç¨± (å»ºç«‹ One-Hot Columns)
all_actions = set()

# å…ˆæŠŠå­—ä¸²è½‰å› Dictionaryï¼Œä¸¦æ”¶é›†æ‰€æœ‰å‹•ä½œ
parsed_menus = []
for menu_str in df['èœå–®']:
    # ä½¿ç”¨ ast.literal_eval å®‰å…¨åœ°å°‡å­—ä¸²è½‰ç‚º Dict
    menu_dict = ast.literal_eval(menu_str)
    parsed_menus.append(menu_dict)
    
    # éæ­·æ‰€æœ‰éƒ¨ä½çš„å‹•ä½œåˆ—è¡¨
    for part_list in menu_dict.values():
        for action in part_list:
            all_actions.add(action)

sorted_actions = sorted(list(all_actions))
print(f"âœ… åµæ¸¬åˆ° {len(sorted_actions)} ç¨®ä¸åŒçš„å¥èº«å‹•ä½œã€‚")

# 3. å»ºç«‹å‹•ä½œçš„ One-Hot Encoding (æœ‰åšè©²å‹•ä½œ=1, æ²’åš=0)
# å»ºç«‹ä¸€å€‹ç©ºçš„ DataFrame ä¾†è£å‹•ä½œæ¨™ç±¤
action_df_data = []

for menu_dict in parsed_menus:
    # æ¯ä¸€åˆ—å…ˆå…¨éƒ¨å¡« 0
    row_data = {f"act_{action}": 0 for action in sorted_actions}
    
    # å°‡æœ‰åšåˆ°çš„å‹•ä½œå¡« 1
    for part_list in menu_dict.values():
        for action in part_list:
            row_data[f"act_{action}"] = 1
    
    action_df_data.append(row_data)

action_df = pd.DataFrame(action_df_data)

# 4. åˆä½µåŸå§‹è³‡æ–™èˆ‡å‹•ä½œæ¨™ç±¤
# åªä¿ç•™æ•¸å€¼å‹ç‰¹å¾µï¼Œå»æ‰åŸæœ¬çš„æ–‡å­—å‹ 'èœå–®' æ¬„ä½
cols_to_keep = [
    'æ€§åˆ¥', 'å¹´ç´€', 'é«”é‡', 'é›£åº¦',
    'chest_max', 'shoulder_max', 'hand_max', 'back_max', 'belly_max', 'leg_max',
    'èƒ¸é«”åŠ›å€¼', 'è‚©é«”åŠ›å€¼', 'æ‰‹é«”åŠ›å€¼', 'èƒŒé«”åŠ›å€¼', 'è…¹é«”åŠ›å€¼', 'è…¿é«”åŠ›å€¼',
    'èœå–®è©•åˆ†'
]

final_df = pd.concat([df[cols_to_keep], action_df], axis=1)

# 5. è¼¸å‡ºçµæœ
output_filename = "processed_dataset.csv"
final_df.to_csv(output_filename, index=False)
print(f"ğŸ‰ è™•ç†å®Œæˆï¼å·²å„²å­˜ç‚º '{output_filename}'ï¼Œå¯ä»¥ç”¨ä¾†è¨“ç·´äº†ã€‚")
